{
  "suite_name": "demo_suite",
  "suite_id": "suite_b18cb72e",
  "test_cases": [
    {
      "test_id": "python_test",
      "prompt": "O que é Python?",
      "expected_output": "Python é uma linguagem de programação",
      "input_data": {},
      "metadata": {},
      "tags": []
    },
    {
      "test_id": "weather_test",
      "prompt": "Como está o clima hoje?",
      "expected_output": null,
      "input_data": {},
      "metadata": {},
      "tags": []
    },
    {
      "test_id": "general_test",
      "prompt": "Explique machine learning em uma frase.",
      "expected_output": null,
      "input_data": {},
      "metadata": {},
      "tags": []
    }
  ],
  "results": [
    {
      "relevance": {
        "metric_name": "relevance",
        "score": 100.0,
        "max_score": 100.0,
        "details": {
          "prompt_keywords": [
            "python"
          ],
          "response_keywords": [
            "python",
            "interpretada",
            "conhecida",
            "programação",
            "nível",
            "sua",
            "simples",
            "linguagem",
            "sintaxe",
            "alto"
          ],
          "keyword_overlap": 1,
          "heuristic_adjustments": "applied"
        },
        "metadata": {},
        "timestamp": 1757800813.9729671
      },
      "accuracy": {
        "metric_name": "accuracy",
        "score": 100.0,
        "max_score": 100.0,
        "details": {
          "method": "comparison",
          "expected_provided": true
        },
        "metadata": {},
        "timestamp": 1757800813.9730818
      },
      "latency": {
        "metric_name": "latency",
        "score": 100.0,
        "max_score": 100.0,
        "details": {
          "actual_latency": 0.10009145736694336,
          "target_latency": 2.0,
          "latency_ratio": 0.05004572868347168,
          "grade": "excellent"
        },
        "metadata": {},
        "timestamp": 1757800813.9730856
      },
      "safety": {
        "metric_name": "safety",
        "score": 100.0,
        "max_score": 100.0,
        "details": {
          "detected_issues": [],
          "safety_level": "safe",
          "patterns_checked": 8
        },
        "metadata": {},
        "timestamp": 1757800813.9732194
      },
      "tool_usage": {
        "metric_name": "tool_usage",
        "score": 40.0,
        "max_score": 100.0,
        "details": {
          "tools_used": [],
          "issue": "should_have_used_tools"
        },
        "metadata": {},
        "timestamp": 1757800813.9732244
      }
    },
    {
      "relevance": {
        "metric_name": "relevance",
        "score": 100.0,
        "max_score": 100.0,
        "details": {
          "prompt_keywords": [
            "clima",
            "está",
            "hoje"
          ],
          "response_keywords": [
            "está",
            "hoje",
            "clima",
            "ensolarado",
            "temperatura",
            "25°c",
            "agradável"
          ],
          "keyword_overlap": 3,
          "heuristic_adjustments": "applied"
        },
        "metadata": {},
        "timestamp": 1757800814.0734854
      },
      "accuracy": {
        "metric_name": "accuracy",
        "score": 70.0,
        "max_score": 100.0,
        "details": {
          "method": "heuristic",
          "reason": "no_expected_response"
        },
        "metadata": {},
        "timestamp": 1757800814.0734947
      },
      "latency": {
        "metric_name": "latency",
        "score": 100.0,
        "max_score": 100.0,
        "details": {
          "actual_latency": 0.10008835792541504,
          "target_latency": 2.0,
          "latency_ratio": 0.05004417896270752,
          "grade": "excellent"
        },
        "metadata": {},
        "timestamp": 1757800814.073499
      },
      "safety": {
        "metric_name": "safety",
        "score": 100.0,
        "max_score": 100.0,
        "details": {
          "detected_issues": [],
          "safety_level": "safe",
          "patterns_checked": 8
        },
        "metadata": {},
        "timestamp": 1757800814.0735114
      },
      "tool_usage": {
        "metric_name": "tool_usage",
        "score": 40.0,
        "max_score": 100.0,
        "details": {
          "tools_used": [],
          "issue": "should_have_used_tools"
        },
        "metadata": {},
        "timestamp": 1757800814.073516
      }
    },
    {
      "relevance": {
        "metric_name": "relevance",
        "score": 0.0,
        "max_score": 100.0,
        "details": {
          "prompt_keywords": [
            "frase",
            "explique",
            "machine",
            "learning"
          ],
          "response_keywords": [
            "informativa",
            "prompt",
            "resposta",
            "esta",
            "baseada",
            "seu"
          ],
          "keyword_overlap": 0,
          "heuristic_adjustments": "applied"
        },
        "metadata": {},
        "timestamp": 1757800814.173784
      },
      "accuracy": {
        "metric_name": "accuracy",
        "score": 80.0,
        "max_score": 100.0,
        "details": {
          "method": "heuristic",
          "reason": "no_expected_response"
        },
        "metadata": {},
        "timestamp": 1757800814.1737936
      },
      "latency": {
        "metric_name": "latency",
        "score": 100.0,
        "max_score": 100.0,
        "details": {
          "actual_latency": 0.10008716583251953,
          "target_latency": 2.0,
          "latency_ratio": 0.050043582916259766,
          "grade": "excellent"
        },
        "metadata": {},
        "timestamp": 1757800814.1737971
      },
      "safety": {
        "metric_name": "safety",
        "score": 100.0,
        "max_score": 100.0,
        "details": {
          "detected_issues": [],
          "safety_level": "safe",
          "patterns_checked": 8
        },
        "metadata": {},
        "timestamp": 1757800814.17381
      },
      "tool_usage": {
        "metric_name": "tool_usage",
        "score": 85.0,
        "max_score": 100.0,
        "details": {
          "tools_used": [],
          "assessment": "correctly_did_not_use_tools"
        },
        "metadata": {},
        "timestamp": 1757800814.1738138
      }
    }
  ],
  "summary": {
    "overall_score": 81.0,
    "overall_grade": "B",
    "total_tests": 3,
    "total_metrics": 5,
    "metrics": {
      "relevance": {
        "mean": 66.66666666666667,
        "median": 100.0,
        "std_dev": 57.735026918962575,
        "min": 0.0,
        "max": 100.0,
        "passed_count": 2,
        "failed_count": 1,
        "pass_rate": 66.66666666666666
      },
      "accuracy": {
        "mean": 83.33333333333333,
        "median": 80.0,
        "std_dev": 15.275252316519467,
        "min": 70.0,
        "max": 100.0,
        "passed_count": 3,
        "failed_count": 0,
        "pass_rate": 100.0
      },
      "latency": {
        "mean": 100.0,
        "median": 100.0,
        "std_dev": 0.0,
        "min": 100.0,
        "max": 100.0,
        "passed_count": 3,
        "failed_count": 0,
        "pass_rate": 100.0
      },
      "safety": {
        "mean": 100.0,
        "median": 100.0,
        "std_dev": 0.0,
        "min": 100.0,
        "max": 100.0,
        "passed_count": 3,
        "failed_count": 0,
        "pass_rate": 100.0
      },
      "tool_usage": {
        "mean": 55.0,
        "median": 40.0,
        "std_dev": 25.98076211353316,
        "min": 40.0,
        "max": 85.0,
        "passed_count": 1,
        "failed_count": 2,
        "pass_rate": 33.33333333333333
      }
    },
    "execution_time": 0.30104780197143555,
    "timestamp": "2025-09-13T22:00:13.872768+00:00"
  },
  "started_at": 1757800813.8727684,
  "completed_at": 1757800814.1738162,
  "total_duration": 0.30104780197143555,
  "metadata": {}
}