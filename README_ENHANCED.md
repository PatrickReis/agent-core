# Agent Core Enhanced üöÄ

**Template completo para desenvolvimento de agentes LangGraph com funcionalidades empresariais avan√ßadas.**

Este projeto serve como archetype/template base para cria√ß√£o de novos agentes LangGraph e servidores MCP com funcionalidades empresariais completas.

## ‚ú® Funcionalidades Principais

### üéõÔ∏è **Sistema de Feature Toggles**
- Controle granular de funcionalidades via configura√ß√£o
- Decorators `@require_feature` e `@optional_feature`
- Rollout percentage e user whitelist
- Configura√ß√£o por ambiente (dev/staging/prod)
- Dependencies entre features

### üìù **Enhanced Logging Estruturado**
- Logs estruturados em JSON com contexto
- M√©tricas autom√°ticas (lat√™ncia, success rate)
- Context variables para tracing distribu√≠do
- TimingContext para medi√ß√£o autom√°tica
- M√∫ltiplos handlers (console, arquivo, m√©tricas)

### üîê **Autentica√ß√£o OAuth2**
- Middleware OAuth2 para MCP Server
- Valida√ß√£o JWT com JWKS cache
- Cliente OAuth2 para service-to-service
- Prote√ß√£o de tools por scopes
- Integra√ß√£o com AWS Secrets Manager

### üß† **Reasoning Avan√ßado**
- Reasoning multi-step com reflex√£o
- An√°lise autom√°tica de complexidade
- Traces completos de racioc√≠nio
- Orquestra√ß√£o inteligente baseada na pergunta
- Adapta√ß√£o din√¢mica do processo

### üìä **Sistema de Avalia√ß√£o (Evals)**
- Framework completo de avalia√ß√£o de prompts
- M√∫ltiplas m√©tricas (relev√¢ncia, acur√°cia, lat√™ncia, seguran√ßa)
- Builder pattern para cria√ß√£o de suites
- Relat√≥rios com agrega√ß√µes estat√≠sticas
- Integra√ß√£o com feature toggles

### ‚ö° **Deployment e Infra**
- **MCP Server Enhanced** com todas as funcionalidades
- **Lambda Handler** otimizado para AWS
- **Docker** multi-stage para dev/prod/lambda
- Cold start mitigation
- Health checks e monitoring

## üèóÔ∏è Arquitetura

```
agent-core-enhanced/
‚îú‚îÄ‚îÄ utils/                     # Funcionalidades aprimoradas
‚îÇ   ‚îú‚îÄ‚îÄ feature_toggles.py     # Sistema de feature toggles
‚îÇ   ‚îú‚îÄ‚îÄ enhanced_logging.py    # Logging estruturado com m√©tricas
‚îÇ   ‚îú‚îÄ‚îÄ oauth2_auth.py         # Autentica√ß√£o OAuth2 completa
‚îÇ   ‚îú‚îÄ‚îÄ advanced_reasoning.py  # Reasoning multi-step
‚îÇ   ‚îú‚îÄ‚îÄ prompt_evals.py        # Framework de avalia√ß√£o
‚îÇ   ‚îî‚îÄ‚îÄ openapi_to_tools.py    # Utilit√°rio migra√ß√£o tools
‚îú‚îÄ‚îÄ mcp_server_enhanced.py     # Servidor MCP com todas features
‚îú‚îÄ‚îÄ lambda_handler.py          # Handler otimizado para AWS Lambda
‚îú‚îÄ‚îÄ integration_test.py        # Testes completos de integra√ß√£o
‚îú‚îÄ‚îÄ feature_toggles.json       # Configura√ß√£o de features
‚îú‚îÄ‚îÄ requirements-lambda.txt    # Deps espec√≠ficas Lambda
‚îú‚îÄ‚îÄ Dockerfile                 # Multi-stage para todos ambientes
‚îî‚îÄ‚îÄ scripts/
    ‚îú‚îÄ‚îÄ setup-dev.sh           # Setup autom√°tico desenvolvimento
    ‚îî‚îÄ‚îÄ test-features.sh       # Teste do sistema de features
```

## üöÄ Quick Start

### 1. Setup Autom√°tico
```bash
# Clone e configure automaticamente
git clone <repo>
cd agent-core-enhanced
chmod +x scripts/setup-dev.sh
./scripts/setup-dev.sh
```

### 2. Configura√ß√£o Manual

```bash
# Instalar depend√™ncias
pip install -r requirements.txt

# Configurar ambiente
cp .env.example .env
# Edite .env com suas configura√ß√µes

# Teste de integra√ß√£o
python integration_test.py
```

### 3. Executar

```bash
# Servidor MCP Enhanced
python mcp_server_enhanced.py

# Ou com MCP CLI
mcp dev mcp_server_enhanced.py

# Lambda local (opcional)
python lambda_handler.py
```

## ‚öôÔ∏è Configura√ß√£o de Features

Configure features via vari√°veis de ambiente ou arquivo `feature_toggles.json`:

```bash
# Habilitar/desabilitar features
FEATURE_ADVANCED_REASONING_ENABLED=true
FEATURE_PROMPT_EVALUATION_ENABLED=true
FEATURE_OAUTH2_AUTHENTICATION_ENABLED=false
FEATURE_ENHANCED_LOGGING_ENABLED=true

# Configura√ß√£o por ambiente
ENVIRONMENT=dev  # dev, staging, prod, lambda
```

### Features Dispon√≠veis:

| Feature | Descri√ß√£o | Ambientes Padr√£o |
|---------|-----------|------------------|
| `advanced_reasoning` | Reasoning multi-step com reflex√£o | todos |
| `prompt_evaluation` | Sistema de avalia√ß√£o de prompts | dev, staging |
| `oauth2_authentication` | Autentica√ß√£o OAuth2 completa | staging, prod |
| `enhanced_logging` | Logging estruturado com m√©tricas | todos |
| `performance_monitoring` | Monitoramento e m√©tricas | todos |
| `experimental_features` | Features em desenvolvimento | dev apenas |

## üìã Exemplos de Uso

### Feature Toggles
```python
from utils.feature_toggles import require_feature, is_feature_enabled

@require_feature("advanced_reasoning")
def complex_analysis(data):
    # C√≥digo que s√≥ executa se feature estiver habilitada
    return enhanced_process(data)

# Verifica√ß√£o manual
if is_feature_enabled("prompt_evaluation"):
    run_evaluation()
```

### Enhanced Logging
```python
from utils.enhanced_logging import get_enhanced_logger, TimingContext

logger = get_enhanced_logger("my_component")

# Log com contexto autom√°tico
logger.info("Processando request", user_id="123", operation="query")

# Timing autom√°tico
with TimingContext("database_query", logger):
    result = database.query(sql)  # Automaticamente medido e logado
```

### Advanced Reasoning
```python
from utils.advanced_reasoning import reason_about

# Reasoning autom√°tico baseado na complexidade
trace = reason_about("Como implementar microservi√ßos em Python?")

print(f"Resposta: {trace.final_answer}")
print(f"Complexidade: {trace.complexity.value}")
print(f"Steps executados: {len(trace.steps)}")
```

### Prompt Evaluation
```python
from utils.prompt_evals import create_standard_eval_suite, run_quick_eval

# Avalia√ß√£o r√°pida
results = run_quick_eval(
    prompts=["O que √© Python?", "Como usar FastAPI?"],
    agent_function=my_agent
)
print(f"Score m√©dio: {sum(results.values()) / len(results):.1f}%")
```

## üîß Deploy em Produ√ß√£o

### Docker
```bash
# Development
docker build --target development -t agent-core:dev .
docker run -p 8000:8000 --env-file .env agent-core:dev

# Production
docker build --target production -t agent-core:prod .
docker run -p 8000:8000 -e ENVIRONMENT=prod agent-core:prod

# Lambda
docker build --target lambda -t agent-core:lambda .
```

### AWS Lambda
```bash
# Build e deploy
docker build --target lambda -t agent-core:lambda .
aws ecr get-login-password | docker login --username AWS --password-stdin <account>.dkr.ecr.<region>.amazonaws.com
docker tag agent-core:lambda <account>.dkr.ecr.<region>.amazonaws.com/agent-core:lambda
docker push <account>.dkr.ecr.<region>.amazonaws.com/agent-core:lambda

# Criar fun√ß√£o Lambda
aws lambda create-function \
  --function-name agent-core \
  --code ImageUri=<account>.dkr.ecr.<region>.amazonaws.com/agent-core:lambda \
  --role arn:aws:iam::<account>:role/lambda-execution-role \
  --timeout 300 \
  --memory-size 1024
```

### Kubernetes (exemplo)
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: agent-core
spec:
  replicas: 3
  selector:
    matchLabels:
      app: agent-core
  template:
    metadata:
      labels:
        app: agent-core
    spec:
      containers:
      - name: agent-core
        image: agent-core:prod
        ports:
        - containerPort: 8000
        env:
        - name: ENVIRONMENT
          value: "prod"
        - name: FEATURE_OAUTH2_AUTHENTICATION_ENABLED
          value: "true"
```

## üß™ Testes e Valida√ß√£o

### Testes de Integra√ß√£o
```bash
# Teste completo
python integration_test.py

# Teste espec√≠fico de features
./scripts/test-features.sh

# Teste de performance
python -c "
from utils.enhanced_logging import get_enhanced_logger
from utils.feature_toggles import is_feature_enabled
import time

for i in range(1000):
    is_feature_enabled('advanced_reasoning')
"
```

### Health Checks
```bash
# Via MCP Server Enhanced
curl http://localhost:8000/health

# Via Lambda Handler
curl -X POST https://your-api.amazonaws.com/health
```

## üìä Monitoramento

### M√©tricas Dispon√≠veis
- **Feature Toggle Usage**: Quais features est√£o sendo usadas
- **Operation Timing**: Lat√™ncia de opera√ß√µes cr√≠ticas
- **Success/Error Rates**: Taxa de sucesso por opera√ß√£o
- **Reasoning Complexity**: Distribui√ß√£o de complexidade das perguntas
- **Evaluation Scores**: Scores de qualidade dos prompts

### Logs Estruturados
```json
{
  "timestamp": "2024-01-15T10:30:45Z",
  "level": "INFO",
  "logger": "agent_core.reasoning",
  "message": "Reasoning conclu√≠do",
  "context": {
    "request_id": "req-123",
    "user_id": "user-456",
    "operation_name": "advanced_reasoning"
  },
  "duration_ms": 1250,
  "confidence": 0.85,
  "steps_executed": 4
}
```

## üéØ Usar como Template

### Para Novo Projeto
1. Clone este reposit√≥rio
2. Renomeie para seu projeto
3. Customize `feature_toggles.json` com suas features
4. Modifique `tools/tools.py` com suas tools espec√≠ficas
5. Ajuste `providers/llm_providers.py` para seu provider
6. Configure `.env` para seu ambiente

### Features que Podem ser Removidas
- **OAuth2**: Remova se n√£o precisar de autentica√ß√£o
- **Prompt Evals**: Remova se n√£o fizer avalia√ß√µes sistem√°ticas
- **Advanced Reasoning**: Use reasoning b√°sico se n√£o precisar de multi-step
- **Lambda Handler**: Remova se n√£o deployar em Lambda

### Customiza√ß√µes Comuns
```python
# Adicionar nova feature
# 1. Em feature_toggles.json
{
  "my_custom_feature": {
    "enabled": true,
    "description": "Minha feature customizada",
    "environments": ["dev", "prod"]
  }
}

# 2. No c√≥digo
from utils.feature_toggles import require_feature

@require_feature("my_custom_feature")
def my_custom_function():
    return "Feature executada!"
```

## üìö Documenta√ß√£o Avan√ßada

### APIs Dispon√≠veis

#### MCP Tools
- `enhanced_reasoning(question, complexity_override=None)`: Reasoning avan√ßado
- `run_agent_evaluation(test_prompts, suite_name)`: Executa avalia√ß√µes
- `manage_features(action, feature_name=None)`: Gerencia feature toggles
- `get_reasoning_trace(trace_id)`: Obt√©m trace de reasoning

#### MCP Resources
- `config://enhanced`: Configura√ß√£o completa do servidor
- `metrics://system`: M√©tricas b√°sicas do sistema
- `metrics://detailed`: M√©tricas detalhadas (requer permiss√£o)
- `health://check`: Health check completo

#### Lambda Endpoints
- `GET /health`: Health check
- `POST /query`: Query principal ao agente
- `POST /evaluate`: Executa avalia√ß√µes
- `GET /metrics`: M√©tricas do sistema
- `POST /features`: Gerencia feature toggles

## ‚ö†Ô∏è Considera√ß√µes de Seguran√ßa

### OAuth2 em Produ√ß√£o
```bash
# Use AWS Secrets Manager
AWS_SECRET_NAME=agent-core-oauth2-secrets
AWS_SECRET_REGION=us-east-1

# Ou configure manualmente
OAUTH2_ISSUER=https://your-auth-server.com
OAUTH2_CLIENT_ID=your_client_id
OAUTH2_CLIENT_SECRET=your_client_secret
```

### Rate Limiting
```bash
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REQUESTS_PER_MINUTE=60
```

### CORS em Produ√ß√£o
```bash
CORS_ORIGINS=https://yourdomain.com
CORS_METHODS=GET,POST
```

## üêõ Troubleshooting

### Feature Toggle n√£o funciona
```bash
# Verifique vari√°veis de ambiente
env | grep FEATURE_

# Teste manualmente
python -c "from utils.feature_toggles import is_feature_enabled; print(is_feature_enabled('advanced_reasoning'))"
```

### Enhanced Logging sem output
```bash
# Verifique n√≠vel de log
export LOG_LEVEL=DEBUG

# Verifique diret√≥rio logs
ls -la logs/
```

### OAuth2 falha na valida√ß√£o
```bash
# Teste conectividade JWKS
curl -v https://your-auth-server.com/.well-known/jwks.json

# Verifique configura√ß√£o
python -c "from utils.oauth2_auth import OAuth2Config; print(OAuth2Config.from_env())"
```

## ü§ù Contribui√ß√£o

1. Fork o projeto
2. Crie branch para feature (`git checkout -b feature/AmazingFeature`)
3. Execute testes (`python integration_test.py`)
4. Commit mudan√ßas (`git commit -m 'Add AmazingFeature'`)
5. Push para branch (`git push origin feature/AmazingFeature`)
6. Abra Pull Request

## üìÑ Licen√ßa

Distribu√≠do sob licen√ßa MIT. Veja `LICENSE` para mais informa√ß√µes.

## üéØ Roadmap

### Pr√≥ximas Funcionalidades
- [ ] Integration com OpenTelemetry
- [ ] Support para Redis cache
- [ ] GraphQL API opcional
- [ ] Kubernetes Operators
- [ ] Multi-tenant support
- [ ] A/B testing framework integrado

### Melhorias Planejadas
- [ ] Performance optimizations
- [ ] Enhanced security features
- [ ] Better error handling
- [ ] Comprehensive documentation
- [ ] Video tutorials

---

**Agent Core Enhanced** - Template completo para agentes LangGraph empresariais üöÄ



  üèóÔ∏è Arquitetura do Sistema

  1. MCP Server Enhanced (mcp_server_enhanced.py)

  Como funciona como servidor MCP:
  - Usa FastMCP para criar servidor compat√≠vel com protocolo MCP
  - Registra tools, resources e prompts que clientes podem chamar
  - Servidor fica "ouvindo" e responde a chamadas via protocolo MCP
  - Clientes (como Claude Desktop) se conectam e podem executar as funcionalidades

  Estrutura principal:
  mcp_server_enhanced.py
  ‚îú‚îÄ‚îÄ Carrega depend√™ncias (tools, graphs, providers)
  ‚îú‚îÄ‚îÄ Configura features via feature_toggles
  ‚îú‚îÄ‚îÄ Registra tools MCP (@mcp.tool)
  ‚îú‚îÄ‚îÄ Registra resources MCP (@mcp.resource) 
  ‚îú‚îÄ‚îÄ Registra prompts MCP (@mcp.prompt)
  ‚îî‚îÄ‚îÄ Inicia servidor (mcp.run())

  2. Sistema de Feature Toggles (utils/feature_toggles.py)

  Prop√≥sito: Controla quais funcionalidades est√£o ativas/inativas dinamicamente

  Funcionamento:
  - Arquivo JSON (feature_toggles.json) define o estado das features
  - Cada feature tem: enabled, environments, rollout_percentage, dependencies
  - Sistema verifica em runtime se feature est√° habilitada antes de executar
  - Permite ligar/desligar funcionalidades sem redeploy

  Features habilitadas no seu sistema:
  - prompt_evaluation - Sistema de evals
  - advanced_reasoning - Reasoning multi-step
  - enhanced_logging - Logging estruturado
  - performance_monitoring - Monitoramento

  3. Sistema de Avalia√ß√£o (utils/prompt_evals.py)

  Como funciona o sistema de evals:

  Arquitetura do Eval Framework:
  EvalFramework
  ‚îú‚îÄ‚îÄ EvalSuiteBuilder (constr√≥i suites de teste)
  ‚îú‚îÄ‚îÄ EvalSuite (executa testes)
  ‚îú‚îÄ‚îÄ BaseEvaluator (classe base para m√©tricas)
  ‚îú‚îÄ‚îÄ Evaluators espec√≠ficos (RelevanceEvaluator, AccuracyEvaluator, etc.)
  ‚îî‚îÄ‚îÄ EvalResult (resultados com scores)

  Fluxo de avalia√ß√£o:
  1. Cria√ß√£o: Builder cria suite com casos de teste + evaluators
  2. Execu√ß√£o: Suite executa cada teste no agente
  3. Avalia√ß√£o: Cada evaluator analisa resposta e gera score
  4. Agrega√ß√£o: Calcula estat√≠sticas finais (m√©dia, mediana, taxa de aprova√ß√£o)
  5. Relat√≥rio: Gera relat√≥rio completo com m√©tricas

  Evaluators implementados:
  - RelevanceEvaluator: Analisa keywords entre prompt/resposta
  - AccuracyEvaluator: Compara com resposta esperada
  - LatencyEvaluator: Mede tempo de resposta vs target
  - SafetyEvaluator: Detecta padr√µes inseguros via regex
  - ToolUsageEvaluator: Verifica uso apropriado de tools

  4. Como Funciona como Agente

  Integra√ß√£o LangChain/LangGraph:
  - transform/lang_mcp_transform.py converte tools LangChain para MCP
  - graphs/graph.py define o grafo do agente (estados, transi√ß√µes)
  - tools/tools.py cont√©m ferramentas (weather, knowledge base, etc.)
  - providers/llm_providers.py abstrai diferentes LLMs

  Fluxo do agente:
  1. Entrada: Recebe query via MCP
  2. Processamento: LangGraph executa states/nodes do grafo
  3. Reasoning: Sistema de reasoning avan√ßado (se habilitado)
  4. Tools: Chama ferramentas quando necess√°rio
  5. Resposta: Retorna resultado estruturado via MCP

  5. Advanced Reasoning System

  Como funciona o reasoning avan√ßado:
  - Analisa complexidade da pergunta (simple/moderate/complex/advanced)
  - Executa steps de reasoning em sequ√™ncia
  - Cada step pode ser: analysis, tool_usage, reflection, synthesis
  - Gera trace completo com confian√ßa e m√©tricas
  - Permite obter traces detalhados posteriormente

  6. Enhanced Logging & Monitoring

  Sistema de observabilidade:
  - Logging estruturado com contexto e timing
  - M√©tricas de performance autom√°ticas
  - Context tracing para debugar fluxos
  - Integra√ß√£o com feature toggles

  üîÑ Fluxo Completo de Funcionamento

  Quando voc√™ executa uma avalia√ß√£o:

  1. Cliente MCP chama tool run_agent_evaluation
  2. Servidor MCP valida se feature prompt_evaluation est√° ativa
  3. EvalFramework cria suite com evaluators padr√£o
  4. Para cada teste:
    - Executa agente LangGraph com o prompt
    - Mede tempo de execu√ß√£o
    - Cada evaluator analisa a resposta
    - Gera scores individuais
  5. Agrega resultados e calcula estat√≠sticas finais
  6. Retorna relat√≥rio completo via MCP

  Integra√ß√£o entre componentes:
  - MCP Server = Interface de comunica√ß√£o
  - Feature Toggles = Controle de funcionalidades
  - Eval System = Qualidade e m√©tricas
  - Agent Graph = L√≥gica de processamento
  - Enhanced Logging = Observabilidade

  Essa arquitetura permite que o sistema funcione como um agente inteligente (via LangGraph) acess√≠vel via MCP (para clientes) com 
  sistema robusto de avalia√ß√£o (para garantir qualidade) e controle din√¢mico de features (para flexibilidade operacional).



  üõ†Ô∏è Utilities Criadas:

  1. utils/eval_runner.py - Execu√ß√£o Individual

  # Teste b√°sico com agente mock
  python utils/eval_runner.py --agent mock --suite basic

  # Teste com agente local
  python utils/eval_runner.py --agent local --suite reasoning --save

  # Avalia√ß√£o r√°pida com prompts personalizados
  python utils/eval_runner.py --agent mock --quick "O que √© Python?,Capital do Brasil?"

  # Usar prompts de arquivo
  python utils/eval_runner.py --agent local --custom-prompts my_prompts.txt

  2. utils/model_comparison.py - Compara√ß√£o de Modelos

  # Comparar modelos espec√≠ficos
  python utils/model_comparison.py --models local_agent,mock_agent --suite basic

  # Modo interativo
  python utils/model_comparison.py --interactive

  # Listar op√ß√µes dispon√≠veis
  python utils/model_comparison.py --list-models
  python utils/model_comparison.py --list-suites

  3. utils/eval_reporter.py - Gera√ß√£o de Relat√≥rios

  # Gerar relat√≥rio HTML
  python utils/eval_reporter.py --input results.json --format html

  # M√∫ltiplos formatos
  python utils/eval_reporter.py --input comparison.json --format all

  # Processar diret√≥rio inteiro
  python utils/eval_reporter.py --directory eval_results --format html

  4. config/eval_models.json - Configura√ß√£o Central

  - Modelos dispon√≠veis (GPT-4, Claude, Local Agent, Mock)
  - Suites de teste pr√©-configuradas
  - Configura√ß√µes de evaluators
  - Presets de compara√ß√£o

  üéØ Fluxo Completo de Uso:

  Teste Individual:

  python utils/eval_runner.py --agent local --suite comprehensive --save

  Compara√ß√£o de Modelos:

  python utils/model_comparison.py --models local_agent,mock_agent --suite reasoning --save-report

  Gera√ß√£o de Relat√≥rio:

  python utils/eval_reporter.py --input comparison_results_*.json --format html

  üìä Recursos Inclu√≠dos:

  - 5 Suites de teste: basic, reasoning, technical, performance, tools_usage
  - 6 Modelos configurados: GPT-4, GPT-3.5, Claude Sonnet/Haiku, Local Agent, Mock
  - 5 M√©tricas autom√°ticas: relevance, accuracy, latency, safety, tool_usage
  - 4 Formatos de relat√≥rio: HTML, JSON, CSV, Markdown
  - Modo interativo para sele√ß√£o guiada
  - Configura√ß√£o flex√≠vel via JSON

  Agora voc√™ pode executar testes completos de evals via linha de comando, comparar diferentes modelos e gerar
  relat√≥rios profissionais automaticamente!
  